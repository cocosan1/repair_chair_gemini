# -*- coding: utf-8 -*-

# --- 1. Import Libraries ---
import os
import io
import pandas as pd
import json
import google.generativeai as genai
from PIL import Image
import streamlit as st
import matplotlib.pyplot as plt
import japanize_matplotlib
import time
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
from sklearn.metrics.pairwise import cosine_similarity

# --- Streamlit UI ---
st.set_page_config(layout="centered") 

st.title("ãƒã‚§ã‚¢ç”»åƒæ¤œç´¢app")
st.markdown("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒã‚§ã‚¢ã®ç”»åƒã¨é¡ä¼¼ã®ãƒã‚§ã‚¢ã‚’æ¤œç´¢ãƒ»è¡¨ç¤ºã—ã¾ã™ã€‚")

# # --- 2. Configuration ---
# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¯Streamlitã‚¢ãƒ—ãƒªã®ãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã‚’æƒ³å®š
EXCEL_CLASSIFICATION_PATH = "chair_classification_results.xlsx"
EXCEL_ALL_PATH = "chair_all.xlsx"
IMAGE_FOLDER_PATH = "images" # Streamlitã‚¢ãƒ—ãƒªå†…ã® 'images' ãƒ•ã‚©ãƒ«ãƒ€
PRICE_LIST_EXCEL_PATH = "ä¿®ç†ä¾¡æ ¼ä¸€è¦§appç”¨.xlsx"
COMMENT_EXCEL_PATH = "comment.xlsx"
NOTES_EXCEL_PATH = "ä¿®ç†æ³¨æ„ç‚¹.xlsx" 

# Classification items #
classification_items = {
    "èƒŒã®ãƒ‡ã‚¶ã‚¤ãƒ³": [
        "ç±å¼µã‚Šï¼ˆç±ãŒå¼µã£ã¦ã‚ã‚Œã°ç¸¦æ¡ŸãŒã‚ã£ã¦ã‚‚ç±å¼µã‚Šã§ï¼‰",
        "å¸ƒåˆã¯é©å¼µã‚Šï¼ˆå¸ƒåˆã¯é©ãŒå¼µã£ã¦ã‚ã‚Œã°ç¸¦æ¡ŸãŒã‚ã£ã¦ã‚‚å¸ƒåˆã¯é©å¼µã‚Šã§ï¼‰",
        "æ¨ªæ¿1æš",
        "æ¨ªæ¡Ÿï¼ˆæ¨ªæ¿2æšä»¥ä¸Šã€‚æ¨ªæ¡Ÿã¨ç¸¦æ¡ŸãŒä¸¡æ–¹ã‚ã‚‹å ´åˆã¯æ¨ªæ¡Ÿæ‰±ã„ã€‚ï¼‰",
        "ç¸¦æ¡Ÿ",
        "ãã®ä»–"
    ],
    "åº§é¢": ["æ¿", "å¼µã‚Š"],
    "è‚˜": ["æœ‰", "ç„¡"]
}

# --- 3. Model Loading (Cached) ---
MODULE_HANDLE = "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5"
IMAGE_SIZE = (224, 224)

@st.cache_resource # Cache the model loading
def load_embedding_model():
    """Loads the TensorFlow Hub image embedding model."""
    success_message = None
    try:
        model = hub.load(MODULE_HANDLE)
        success_message = "âœ… ç”»åƒåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†ã€‚"
        return model, success_message
    except Exception as e:
        st.error(f"ğŸš¨ ç”»åƒåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

# --- 4. API Key and Gemini Model Setup (Cached) ---
@st.cache_resource # Cache the Gemini model initialization
def configure_gemini():
    """Configures Gemini API and initializes the model."""
    api_key = None
    success_messages = []
    if 'GEMINI_API_KEY' in st.secrets:
        api_key = st.secrets["GEMINI_API_KEY"]
        try:
            genai.configure(api_key=api_key)
            success_messages.append("âœ… Gemini API Keyã®è¨­å®šå®Œäº†ã€‚")
            model = genai.GenerativeModel('gemini-1.5-flash-latest')
            success_messages.append(f"âœ… Geminiãƒ¢ãƒ‡ãƒ« ({model.model_name}) ã®åˆæœŸåŒ–å®Œäº†ã€‚")
            return model, success_messages
        except Exception as e:
            st.error(f"ğŸš¨ Geminiã®è¨­å®šã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None
    else:
        return None, None

# --- 5. Helper Functions ---
def build_gemini_prompt(items_dict):
    prompt = "Analyze the provided image of a chair and classify it according to the following criteria.\n"
    prompt += "For each criterion, choose EXACTLY ONE option from the provided list.\n"
    prompt += "Output the results ONLY as a valid JSON object with the keys \"èƒŒã®ãƒ‡ã‚¶ã‚¤ãƒ³\", \"åº§é¢\", and \"è‚˜\".\n\n"
    prompt += "Classification Criteria:\n"
    for key, options in items_dict.items():
        prompt += f'- {key}: {options}\n'

    prompt += '\nExample Output Format:\n{\n'
    example_items = []
    for key, options in items_dict.items():
        if options:
            example_value = json.dumps(options[0], ensure_ascii=False)[1:-1]
            example_items.append(f'  "{key}": "{example_value}"')
        else:
            example_items.append(f'  "{key}": "ï¼ˆé¸æŠè‚¢ä¾‹ãªã—ï¼‰"')

    prompt += ",\n".join(example_items)
    prompt += '\n}\n'

    prompt += "Provide only the JSON object in your response."
    return prompt

def validate_gemini_response(response_text, items_dict):
    try:
        if response_text.strip().startswith("```json"): response_text = response_text.strip()[7:-3].strip()
        elif response_text.strip().startswith("```"): response_text = response_text.strip()[3:-3].strip()
        parsed_json = json.loads(response_text)
        if not isinstance(parsed_json, dict): return None, "Error: Gemini response is not a JSON object."
        res = {}
        missing, invalid = [], {}
        for k, opts in items_dict.items():
            if k not in parsed_json: missing.append(k)
            elif parsed_json[k] not in opts: invalid[k] = parsed_json[k]
            else: res[k] = parsed_json[k]
        if missing: return None, f"Error: Missing keys: {', '.join(missing)}"
        if invalid: return None, f"Error: Invalid values: {invalid}"
        return res, None
    except json.JSONDecodeError: return None, f"Error: Could not decode JSON. Response:\n{response_text}"
    except Exception as e: return None, f"Error during validation: {e}"

def classify_image_with_gemini(img_data, items_dict):
    if not gemini_model: return None, "Error: Gemini model not initialized."
    img_pil = Image.open(io.BytesIO(img_data))
    prompt = build_gemini_prompt(items_dict)
    try:
        safety_settings = [ {"category": c, "threshold": "BLOCK_MEDIUM_AND_ABOVE"} for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]]
        response = gemini_model.generate_content(
            [prompt, img_pil],
            generation_config=genai.types.GenerationConfig(temperature=0.1),
            safety_settings=safety_settings,
            stream=False
        )
        if not response.parts:
            block_reason = response.prompt_feedback.block_reason if response.prompt_feedback else "Unknown"
            error_msg = f"Error: Content blocked (Reason: {block_reason})" if block_reason != 0 else "Error: Empty response."
            st.warning(f"Geminiåˆ†é¡ã‚¨ãƒ©ãƒ¼: {error_msg}")
            return None, error_msg
        return validate_gemini_response(response.text, items_dict)
    except Exception as e:
        st.error(f"Gemini APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼ï¼ˆåˆ†é¡ï¼‰: {e}")
        return None, f"Error calling Gemini API for classification: {e}"

def load_and_preprocess_image(image_bytes_or_path, target_size):
    try:
        if isinstance(image_bytes_or_path, bytes):
            img = Image.open(io.BytesIO(image_bytes_or_path)).convert('RGB')
        else:
            if not os.path.exists(image_bytes_or_path):
                st.error(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_bytes_or_path}")
                return None
            img = Image.open(image_bytes_or_path).convert('RGB')
        img = img.resize(target_size)
        img_array = tf.keras.preprocessing.image.img_to_array(img)
        img_array = img_array / 255.0
        return tf.expand_dims(img_array, axis=0)
    except Exception as e:
        st.error(f"ç”»åƒèª­ã¿è¾¼ã¿/å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({'bytes input' if isinstance(image_bytes_or_path, bytes) else image_bytes_or_path}): {e}")
        return None

def get_image_embedding(image_tensor):
    if embedding_model is None:
        st.error("ğŸš¨ ç”»åƒåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return None
    if image_tensor is None:
        st.warning("âš ï¸ åŸ‹ã‚è¾¼ã¿è¨ˆç®—ã®ãŸã‚ã®ç”»åƒãƒ†ãƒ³ã‚½ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return None
    try:
        features = embedding_model(image_tensor)
        return features.numpy()
    except Exception as e:
        st.error(f"ğŸš¨ ç”»åƒåŸ‹ã‚è¾¼ã¿ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def calculate_similarity(embedding1, embedding2):
    if embedding1 is None or embedding2 is None: return 0.0
    embedding1 = embedding1.reshape(1, -1)
    embedding2 = embedding2.reshape(1, -1)
    return cosine_similarity(embedding1, embedding2)[0][0]

def get_gemini_similarity_score(target_img_data, candidate_img_data):
    if not gemini_model: return None
    if not target_img_data or not candidate_img_data: return None
    try:
        target_img_pil = Image.open(io.BytesIO(target_img_data))
        candidate_img_pil = Image.open(io.BytesIO(candidate_img_data))
        prompt = """æä¾›ã•ã‚ŒãŸ2ã¤ã®æ¤…å­ã®ç”»åƒã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
        å¤–è¦³ï¼ˆå½¢çŠ¶ã€ã‚¹ã‚¿ã‚¤ãƒ«ã€ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«ï¼‰ã®ã¿ã«åŸºã¥ã„ã¦ã€è¦–è¦šçš„ãªé¡ä¼¼åº¦ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
        0.00ï¼ˆå…¨ãä¼¼ã¦ã„ãªã„ï¼‰ã‹ã‚‰1.00ï¼ˆåŒä¸€ã¾ãŸã¯ã»ã¼åŒä¸€ï¼‰ã¾ã§ã®å˜ä¸€ã®æµ®å‹•å°æ•°ç‚¹æ•°ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã€èª¬æ˜ã€æ›¸å¼è¨­å®šã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚æ•°å€¤ã ã‘ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚

        å‡ºåŠ›ä¾‹:
        0.75
        """
        safety_settings = [ {"category": c, "threshold": "BLOCK_MEDIUM_AND_ABOVE"} for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]]
        response = gemini_model.generate_content(
            [prompt, target_img_pil, candidate_img_pil],
            generation_config=genai.types.GenerationConfig(temperature=0.0),
            safety_settings=safety_settings,
            stream=False
        )
        if not response.parts:
            block_reason = response.prompt_feedback.block_reason if response.prompt_feedback else "Unknown"
            error_msg = f"ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ–ãƒ­ãƒƒã‚¯ (Reason: {block_reason if block_reason != 0 else 'Empty response'})"
            print(f"Gemini Sim Error: {error_msg}")
            return None
        response_text = response.text.strip()
        try:
            import re
            match = re.search(r"[-+]?\d*\.\d+|\d+", response_text)
            if match:
                score = float(match.group(0))
                if 0.0 <= score <= 1.0: return score
                else:
                    print(f"Gemini Sim Error: ã‚¹ã‚³ã‚¢ãŒç¯„å›²å¤– ({score}). Response: '{response_text}'")
                    return None
            else:
                print(f"Gemini Sim Error: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ Response: '{response_text}'")
                return None
        except ValueError:
            print(f"Gemini Sim Error: ã‚¹ã‚³ã‚¢ã‚’æ•°å€¤ã«å¤‰æ›ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ Response: '{response_text}'")
            return None
    except FileNotFoundError:
        print(f"Gemini Sim Error: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ (å†…éƒ¨ã‚¨ãƒ©ãƒ¼)ã€‚")
        return None
    except Exception as e:
        print(f"Gemini Sim Error: äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return None

# --- 6. Search and Rank Function (Modified) ---
def perform_search_and_rank(search_classifications, target_image_data):
    """Filters, ranks by embedding, re-ranks top 8 by Gemini, shows top 3. Returns detailed lists for debugging."""
    log_messages = []
    fig = None
    filtered_filenames = []
    embedding_ranked_results = []
    gemini_ranked_results = [] # æœ€çµ‚çµæœãƒªã‚¹ãƒˆã‚‚åˆæœŸåŒ–ã—ã¦ãŠã

    log_messages.append("---")
    log_messages.append("ã‚¹ãƒ†ãƒƒãƒ—3: é¡ä¼¼ç”»åƒæ¤œç´¢ & ãƒ©ãƒ³ã‚­ãƒ³ã‚°å‡¦ç† é–‹å§‹")
    log_messages.append("\nğŸ”„ åˆ†é¡çµæœã«åŸºã¥ã„ã¦å€™è£œç”»åƒã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸­...")

    if not os.path.exists(EXCEL_CLASSIFICATION_PATH):
        log_messages.append(f"âŒ ã‚¨ãƒ©ãƒ¼: åˆ†é¡ç”¨Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {EXCEL_CLASSIFICATION_PATH}")
        # <--- ä¿®æ­£: 5ã¤ã®å€¤ã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´
        return None, None, log_messages, None, None
    try:
        df = pd.read_excel(EXCEL_CLASSIFICATION_PATH)
        required_cols = list(classification_items.keys()) + ['ãƒ•ã‚¡ã‚¤ãƒ«å']
        if not all(col in df.columns for col in required_cols):
            missing = [c for c in required_cols if c not in df.columns]
            log_messages.append(f"âŒ ã‚¨ãƒ©ãƒ¼: Excelã«å¿…è¦ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“: {missing}")
            # <--- ä¿®æ­£: 5ã¤ã®å€¤ã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´
            return None, None, log_messages, None, None
        log_messages.append(f"ğŸ“Š åˆ†é¡ç”¨Excelèª­ã¿è¾¼ã¿å®Œäº†: {EXCEL_CLASSIFICATION_PATH} ({len(df)}ä»¶)")
    except Exception as e:
        log_messages.append(f"âŒ ã‚¨ãƒ©ãƒ¼: åˆ†é¡ç”¨Excelèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        # <--- ä¿®æ­£: 5ã¤ã®å€¤ã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´
        return None, None, log_messages, None, None

    mask = pd.Series([True] * len(df))
    try:
        for key, value in search_classifications.items():
            if key in df.columns:
                mask &= (df[key].astype(str).str.strip() == str(value).strip())
            else:
                log_messages.append(f"âš ï¸ Excelã« '{key}' åˆ—ãŒãªã„ãŸã‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        matching_df = df[mask].copy()
    except Exception as e:
        log_messages.append(f"âŒ ã‚¨ãƒ©ãƒ¼: Excelãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
        # <--- ä¿®æ­£: 5ã¤ã®å€¤ã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´
        return None, None, log_messages, None, None

    if matching_df.empty:
        log_messages.append("â„¹ï¸ åˆ†é¡æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å€™è£œç”»åƒã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        # <--- ä¿®æ­£: 5ã¤ã®å€¤ã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´ (ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™)
        return None, None, log_messages, [], []

    if 'ãƒ•ã‚¡ã‚¤ãƒ«å' not in matching_df.columns:
         log_messages.append("âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿ã« 'ãƒ•ã‚¡ã‚¤ãƒ«å' åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
         # <--- ä¿®æ­£: 5ã¤ã®å€¤ã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´
         return None, None, log_messages, None, None

    # <--- ä¿®æ­£ãªã—: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«åãƒªã‚¹ãƒˆã‚’ä¿å­˜
    filtered_filenames = matching_df['ãƒ•ã‚¡ã‚¤ãƒ«å'].dropna().astype(str).str.strip().tolist()
    log_messages.append(f"\nâœ… {len(filtered_filenames)}ä»¶ã®å€™è£œç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ˆåˆ†é¡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œï¼‰ã€‚")

    # --- Perform Embedding Similarity Ranking ---
    if not embedding_model:
         log_messages.append("\nâš ï¸ ç”»åƒåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€é¡ä¼¼åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
         # <--- ä¿®æ­£: 5ã¤ã®å€¤ã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´
         return None, None, log_messages, filtered_filenames, None

    log_messages.append("\nâ³ 1. åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«ã‚ˆã‚‹é¡ä¼¼åº¦ã‚’è¨ˆç®—ä¸­...")
    start_sim_time = time.time()
    target_image_tensor = load_and_preprocess_image(target_image_data, IMAGE_SIZE)
    if target_image_tensor is None:
         log_messages.append("âŒ ã‚¨ãƒ©ãƒ¼: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒã‚’å‡¦ç†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
         # <--- ä¿®æ­£: 5ã¤ã®å€¤ã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´
         return None, None, log_messages, filtered_filenames, None
    target_embedding = get_image_embedding(target_image_tensor)

    if target_embedding is None:
        log_messages.append("âŒ ã‚¨ãƒ©ãƒ¼: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        # <--- ä¿®æ­£: 5ã¤ã®å€¤ã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´
        return None, None, log_messages, filtered_filenames, None

    similarity_results_temp = [] # ä¸€æ™‚çš„ãªãƒªã‚¹ãƒˆ
    processed_count = 0
    if not os.path.isdir(IMAGE_FOLDER_PATH):
        log_messages.append(f"âŒ ã‚¨ãƒ©ãƒ¼: ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {IMAGE_FOLDER_PATH}")
        # <--- ä¿®æ­£: 5ã¤ã®å€¤ã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´
        return None, None, log_messages, filtered_filenames, None

    for filename in filtered_filenames:
        img_path = os.path.join(IMAGE_FOLDER_PATH, filename)
        if not os.path.exists(img_path): continue

        candidate_tensor = load_and_preprocess_image(img_path, IMAGE_SIZE)
        if candidate_tensor is not None:
            candidate_embedding = get_image_embedding(candidate_tensor)
            if candidate_embedding is not None:
                try:
                    similarity_score = calculate_similarity(target_embedding, candidate_embedding)
                    similarity_results_temp.append({"filename": filename, "path": img_path, "score": float(similarity_score)})
                    processed_count += 1
                except Exception as sim_e:
                    log_messages.append(f"   - âš ï¸ åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼ ({filename}): {sim_e}")

    end_sim_time = time.time()
    log_messages.append(f"âœ… åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦è¨ˆç®—å®Œäº† ({processed_count}/{len(filtered_filenames)}ä»¶å‡¦ç†)ã€‚æ™‚é–“: {end_sim_time - start_sim_time:.2f} ç§’")

    if not similarity_results_temp:
         log_messages.append("â„¹ï¸ åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦ã‚’è¨ˆç®—ã§ããŸå€™è£œç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
         # <--- ä¿®æ­£: 5ã¤ã®å€¤ã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´ (ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™)
         return None, None, log_messages, filtered_filenames, []

    # --- Sort by Embedding Similarity and Select Top 8 ---
    similarity_results_temp.sort(key=lambda x: x.get("score", 0.0), reverse=True)
    # <--- ä¿®æ­£ãªã—: åŸ‹ã‚è¾¼ã¿ãƒ©ãƒ³ã‚¯å¾Œã®ãƒªã‚¹ãƒˆã‚’ä¿å­˜ (ä¸Šä½8ä»¶ã«çµã‚‹å‰)
    embedding_ranked_results = similarity_results_temp[:8] # ä¸Šä½8ä»¶ã‚’è¨˜éŒ²
    top_8_candidates = embedding_ranked_results # å¤‰æ•°åç¶­æŒã®ãŸã‚ä»£å…¥

    if not top_8_candidates:
        log_messages.append("â„¹ï¸ åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦ã§ãƒ©ãƒ³ã‚¯ä»˜ã‘ã§ãã‚‹å€™è£œãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        # <--- ä¿®æ­£: 5ã¤ã®å€¤ã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´ (ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™)
        return None, None, log_messages, filtered_filenames, []

    log_messages.append(f"\nâœ… åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦ ä¸Šä½{len(top_8_candidates)}ä»¶ã‚’å–å¾—ã€‚")

    # --- Re-rank Top 8 using Gemini Visual Similarity ---
    log_messages.append(f"\nâ³ 2. ä¸Šä½{len(top_8_candidates)}ä»¶ã«ã¤ã„ã¦ã€Geminiã«ã‚ˆã‚‹è¦–è¦šçš„é¡ä¼¼åº¦ã‚’è©•ä¾¡ä¸­ (æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)...")
    gemini_ranked_results_temp = []
    start_gemini_time = time.time()
    gemini_api_call_count = 0

    for rank, candidate in enumerate(top_8_candidates):
        log_messages.append(f"   - Geminiè©•ä¾¡ä¸­ ({rank+1}/{len(top_8_candidates)}): {candidate['filename']}...")
        try:
            with open(candidate['path'], 'rb') as f: candidate_image_data = f.read()
            gemini_score = get_gemini_similarity_score(target_image_data, candidate_image_data)
            gemini_api_call_count += 1
            candidate['gemini_score'] = gemini_score
            gemini_ranked_results_temp.append(candidate)
            log_messages.append(f"   - Geminiè©•ä¾¡å®Œäº† ({rank+1}/{len(top_8_candidates)}): {candidate['filename']} -> ã‚¹ã‚³ã‚¢: {gemini_score if gemini_score is not None else 'è©•ä¾¡å¤±æ•—/ã‚¨ãƒ©ãƒ¼'}")
        except FileNotFoundError:
            log_messages.append(f"   - âŒ ã‚¨ãƒ©ãƒ¼: Geminiè©•ä¾¡ç”¨ å€™è£œç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {candidate['path']}")
            candidate['gemini_score'] = None
            gemini_ranked_results_temp.append(candidate)
        except Exception as e:
            log_messages.append(f"   - âŒ Geminiè©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ ({candidate['filename']}): {type(e).__name__}: {e}")
            candidate['gemini_score'] = None
            gemini_ranked_results_temp.append(candidate)

    end_gemini_time = time.time()
    total_gemini_time = end_gemini_time - start_gemini_time
    log_messages.append(f"âœ… Geminié¡ä¼¼åº¦è©•ä¾¡å®Œäº† ({gemini_api_call_count}å› APIã‚³ãƒ¼ãƒ«)ã€‚æ™‚é–“: {total_gemini_time:.2f} ç§’")

    # --- Sort by Gemini Score ---
    gemini_ranked_results_temp.sort(key=lambda x: x.get('gemini_score', -1), reverse=True)
    gemini_ranked_results = gemini_ranked_results_temp # æœ€çµ‚çµæœã‚’ä»£å…¥

    # --- Create Figure for Top 3 Images ---
    log_messages.append("\nâœ… ä¸Šä½3ä»¶ã®ç”»åƒè¡¨ç¤ºã‚’æº–å‚™ä¸­...")
    fig = None
    final_top_3_for_figure = gemini_ranked_results[:3]

    if not final_top_3_for_figure:
         log_messages.append("â„¹ï¸ è¡¨ç¤ºã§ãã‚‹ä¸Šä½ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        n_images_to_display = len(final_top_3_for_figure)
        try:
            fig, axes = plt.subplots(1, n_images_to_display, figsize=(n_images_to_display * 4, 5))
            if n_images_to_display == 1: axes = [axes]
            for i, result in enumerate(final_top_3_for_figure):
                    img = Image.open(result["path"])
                    axes[i].imshow(img)
                    embed_score_str = f"{result.get('score', 'N/A'):.3f}" if isinstance(result.get('score'), (int, float)) else "N/A"
                    gemini_score_val = result.get('gemini_score')
                    gemini_score_str = f"{gemini_score_val:.3f}" if isinstance(gemini_score_val, (int, float)) else "è©•ä¾¡å¤±æ•—" if gemini_score_val is None else "N/A"
                    title = f"Rank {i+1}: {result['filename']}\nGemini Sim: {gemini_score_str}\nEmbed Sim: {embed_score_str}"
                    axes[i].set_title(title, fontsize=14)
                    axes[i].axis('off')
            plt.tight_layout(pad=2.0)
            log_messages.append("âœ… ä¸Šä½3ç”»åƒã®æº–å‚™å®Œäº†ã€‚")
        except Exception as e:
            log_messages.append(f"âŒ ã‚¨ãƒ©ãƒ¼: ä¸Šä½3ç”»åƒã®æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
            fig = None

    # --- Return Results, Figure, Logs, and Intermediate Lists ---
    # <--- ä¿®æ­£ãªã—: 5ã¤ã®å€¤ã‚’è¿”ã™
    return gemini_ranked_results, fig, log_messages, filtered_filenames, embedding_ranked_results

# --- 7. Display Product Information ---
def display_product_info(product_number):
    st.markdown("---")
    st.subheader(f"å“ç•ª '{product_number}' ã®è©³ç´°æƒ…å ±")
    if not os.path.exists(EXCEL_ALL_PATH):
        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: è©³ç´°æƒ…å ±Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {EXCEL_ALL_PATH}")
        return
    try:
        df_all = pd.read_excel(EXCEL_ALL_PATH)
    except Exception as e:
        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: è©³ç´°æƒ…å ±Excelèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return
    if 'å“ç•ª' not in df_all.columns:
        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: è©³ç´°æƒ…å ±Excelã« 'å“ç•ª' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    try:
        df_all['å“ç•ª_str'] = df_all['å“ç•ª'].astype(str).str.strip()
        search_term = str(product_number).strip()
        matching_row = df_all[df_all['å“ç•ª_str'] == search_term]
        if matching_row.empty:
            st.warning(f"â„¹ï¸ å“ç•ª '{product_number}' ã«ä¸€è‡´ã™ã‚‹æƒ…å ±ã¯ {EXCEL_ALL_PATH} ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            product_data = matching_row.iloc[0]
            if 'å“ç•ª_str' in product_data.index: product_data = product_data.drop('å“ç•ª_str')
            product_data = product_data.fillna("").astype(str)
            display_df = product_data.reset_index()
            display_df.columns = ['é …ç›®', 'å†…å®¹']
            st.table(display_df.set_index('é …ç›®'))
    except Exception as e:
         st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: è©³ç´°æƒ…å ±ã®æ¤œç´¢ã¾ãŸã¯è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    st.markdown("---")
    st.subheader("é–¢é€£ã‚³ãƒ¡ãƒ³ãƒˆ")
    if not os.path.exists(COMMENT_EXCEL_PATH):
        st.info(f"â„¹ï¸ ã‚³ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ« ({COMMENT_EXCEL_PATH}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    else:
        try:
            df_comment = pd.read_excel(COMMENT_EXCEL_PATH)
            if 'å“ç•ª' not in df_comment.columns:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: ã‚³ãƒ¡ãƒ³ãƒˆExcel ({COMMENT_EXCEL_PATH}) ã« 'å“ç•ª' åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                try:
                    df_comment['å“ç•ª_str'] = df_comment['å“ç•ª'].astype(str).str.strip()
                    search_term_comment = str(product_number).strip()
                    matching_rows_comment = df_comment[df_comment['å“ç•ª_str'] == search_term_comment]
                    if matching_rows_comment.empty:
                        st.info(f"â„¹ï¸ å“ç•ª '{product_number}' ã®ã‚³ãƒ¡ãƒ³ãƒˆã¯ {COMMENT_EXCEL_PATH} ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    else:
                        for index, comment_row in matching_rows_comment.iterrows():
                            if 'å“ç•ª_str' in comment_row.index: comment_row = comment_row.drop('å“ç•ª_str')
                            comment_data = comment_row.fillna("").astype(str)
                            comment_display_df = comment_data.reset_index()
                            comment_display_df.columns = ['é …ç›®', 'å†…å®¹']
                            st.table(comment_display_df.set_index('é …ç›®'))
                            st.markdown("---") # ã‚³ãƒ¡ãƒ³ãƒˆã”ã¨ã«åŒºåˆ‡ã‚Šç·š
                except Exception as e:
                     st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: ã‚³ãƒ¡ãƒ³ãƒˆæƒ…å ±ã®æ¤œç´¢ã¾ãŸã¯è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: ã‚³ãƒ¡ãƒ³ãƒˆExcel ({COMMENT_EXCEL_PATH}) ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# --- 8. Initialize Session State ---
if 'uploaded_file_info' not in st.session_state: st.session_state['uploaded_file_info'] = None
if 'classification_result' not in st.session_state: st.session_state['classification_result'] = None
if 'error_msg' not in st.session_state: st.session_state['error_msg'] = None
if 'top_8_results' not in st.session_state: st.session_state['top_8_results'] = None # Geminiãƒ©ãƒ³ã‚¯å¾Œ (æœ€çµ‚çµæœ)
if 'search_figure' not in st.session_state: st.session_state['search_figure'] = None
if 'selected_product_number' not in st.session_state: st.session_state['selected_product_number'] = None
if 'search_logs' not in st.session_state: st.session_state['search_logs'] = None
if 'filtered_filenames_list' not in st.session_state: st.session_state['filtered_filenames_list'] = None
if 'embedding_ranked_list' not in st.session_state: st.session_state['embedding_ranked_list'] = None

# --- ãƒ¢ãƒ‡ãƒ«ã¨APIã®åˆæœŸåŒ– ---
loading_message_embed = f"ğŸ”„ ç”»åƒåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {MODULE_HANDLE}"
embedding_model, embed_load_msg = load_embedding_model()
gemini_model, gemini_init_msgs = configure_gemini()

# --- ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ ---
api_key_present = 'GEMINI_API_KEY' in st.secrets
files_present = (
    os.path.exists(EXCEL_CLASSIFICATION_PATH) and
    os.path.exists(EXCEL_ALL_PATH) and
    os.path.isdir(IMAGE_FOLDER_PATH) and
    os.path.exists(COMMENT_EXCEL_PATH) and
    os.path.exists(PRICE_LIST_EXCEL_PATH) and
    os.path.exists(NOTES_EXCEL_PATH) # <--- ã“ã®è¡Œã‚’è¿½åŠ 
)
models_ready = gemini_model is not None and embedding_model is not None

# --- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º ---
if not api_key_present: st.error("ğŸš¨ **è¨­å®šã‚¨ãƒ©ãƒ¼:** Streamlit Secretsã« 'GEMINI_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
if not files_present:
    missing_files_msg = "ğŸš¨ **ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼:** å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
    missing_files_msg += f"- åˆ†é¡Excel: {EXCEL_CLASSIFICATION_PATH} {'âœ…' if os.path.exists(EXCEL_CLASSIFICATION_PATH) else 'âŒ'}\n"
    missing_files_msg += f"- è©³ç´°Excel: {EXCEL_ALL_PATH} {'âœ…' if os.path.exists(EXCEL_ALL_PATH) else 'âŒ'}\n"
    missing_files_msg += f"- ç”»åƒãƒ•ã‚©ãƒ«ãƒ€: {IMAGE_FOLDER_PATH} {'âœ…' if os.path.isdir(IMAGE_FOLDER_PATH) else 'âŒ'}\n"
    missing_files_msg += f"- ã‚³ãƒ¡ãƒ³ãƒˆExcel: {COMMENT_EXCEL_PATH} {'âœ…' if os.path.exists(COMMENT_EXCEL_PATH) else 'âŒ'}\n"
    missing_files_msg += f"- ä¿®ç†ä¾¡æ ¼Excel: {PRICE_LIST_EXCEL_PATH} {'âœ…' if os.path.exists(PRICE_LIST_EXCEL_PATH) else 'âŒ'}\n" # <--- æœ«å°¾ã«æ”¹è¡Œã‚’è¿½åŠ 
    missing_files_msg += f"- æ³¨æ„ç‚¹Excel: {NOTES_EXCEL_PATH} {'âœ…' if os.path.exists(NOTES_EXCEL_PATH) else 'âŒ'}" # <--- ã“ã®è¡Œã‚’è¿½åŠ 
    st.error(missing_files_msg)

# --- åˆæœŸåŒ–ãƒ­ã‚°è¡¨ç¤º ---
initialization_messages = [loading_message_embed]
if embed_load_msg: initialization_messages.append(embed_load_msg)
if gemini_init_msgs: initialization_messages.extend(gemini_init_msgs)
if not api_key_present: initialization_messages.append("âš ï¸ Gemini API KeyãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Geminié–¢é€£æ©Ÿèƒ½ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
elif gemini_model is None and not gemini_init_msgs: initialization_messages.append("âš ï¸ Geminiãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚Geminié–¢é€£æ©Ÿèƒ½ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")

if initialization_messages:
    with st.expander("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–ãƒ­ã‚°", expanded=False):
        for msg in initialization_messages:
            if msg.startswith("ğŸ”„"): st.write(msg)
            elif msg.startswith("âœ…"): st.success(msg)
            elif msg.startswith("âš ï¸"): st.warning(msg)
            else: st.write(msg)

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---
if api_key_present and models_ready and files_present:
    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—1: ãƒã‚§ã‚¢ç”»åƒã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

    # è¨±å¯ã™ã‚‹æ‹¡å¼µå­ã®ãƒªã‚¹ãƒˆã«å¤§æ–‡å­—ç‰ˆã‚‚è¿½åŠ 
    # Streamlitã®typeãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯é€šå¸¸ãƒ‰ãƒƒãƒˆãªã—ã®æ‹¡å¼µå­åã‚’æœŸå¾…ã—ã¾ã™
    allowed_extensions = ["jpg", "jpeg", "png", "JPG", "JPEG", "PNG"]

    uploaded_file = st.file_uploader("ãƒã‚§ã‚¢ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ (JPG, PNG)", type=allowed_extensions)
    upload_status_placeholder = st.empty()

    if uploaded_file is not None:
        # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚‰çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        if st.session_state.uploaded_file_info is None or st.session_state.uploaded_file_info['name'] != uploaded_file.name:
            st.session_state.uploaded_file_info = {
                'name': uploaded_file.name, 'type': uploaded_file.type,
                'size': uploaded_file.size, 'data': uploaded_file.getvalue()
            }
            # é–¢é€£ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state.classification_result = None
            st.session_state.error_msg = None
            st.session_state.top_8_results = None
            st.session_state.search_figure = None
            st.session_state.selected_product_number = None
            st.session_state.search_logs = None
            st.session_state.filtered_filenames_list = None
            st.session_state.embedding_ranked_list = None

    if st.session_state.uploaded_file_info:
        with upload_status_placeholder.container():
            st.markdown("##### target image")
            st.image(st.session_state.uploaded_file_info['data'], caption=f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ: {st.session_state.uploaded_file_info['name']}", width=200)

        # --- Step 2: Classification ---
        if st.session_state.classification_result is None and st.session_state.error_msg is None:
             with st.spinner("Geminiã«ã‚ˆã‚‹ç”»åƒã®è‡ªå‹•åˆ†é¡ã‚’å®Ÿè¡Œä¸­..."):
                target_image_data = st.session_state.uploaded_file_info['data']
                classification_result, error_msg = classify_image_with_gemini(target_image_data, classification_items)
                st.session_state.classification_result = classification_result
                st.session_state.error_msg = error_msg

        if st.session_state.error_msg:
            st.error(f"âŒ åˆ†é¡ã‚¨ãƒ©ãƒ¼:\n{st.session_state.error_msg}")
        elif st.session_state.classification_result:
            with st.expander("ã‚¹ãƒ†ãƒƒãƒ—2: è‡ªå‹•åˆ†é¡çµæœ è©³ç´°", expanded=False):
                st.success("âœ… åˆ†é¡çµæœ:")
                class_df = pd.DataFrame(list(st.session_state.classification_result.items()), columns=['é …ç›®', 'åˆ†é¡'])
                st.table(class_df)

            # --- Step 3: Search and Rank ---
            search_logs = []
            # æ¤œç´¢çµæœãŒã¾ã ãªã„å ´åˆã«å®Ÿè¡Œ
            if st.session_state.classification_result and st.session_state.top_8_results is None and st.session_state.filtered_filenames_list is None:
                with st.spinner("ğŸ” é¡ä¼¼ç”»åƒã‚’æ¤œç´¢ãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä¸­... (æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)"):
                    target_image_data = st.session_state.uploaded_file_info['data']
                    # <--- ä¿®æ­£ãªã—: 5ã¤ã®æˆ»ã‚Šå€¤ã‚’å—ã‘å–ã‚‹
                    top_8, fig_top_3, search_logs, filtered_list, embed_list = perform_search_and_rank(
                        st.session_state.classification_result,
                        target_image_data
                    )
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                    st.session_state.top_8_results = top_8
                    st.session_state.search_figure = fig_top_3
                    st.session_state.search_logs = search_logs
                    st.session_state.filtered_filenames_list = filtered_list
                    st.session_state.embedding_ranked_list = embed_list

            # --- ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã®è¡¨ç¤º ---
            st.markdown("---") # åŒºåˆ‡ã‚Š
            st.markdown("###### âš™ï¸ æ¤œç´¢ãƒ—ãƒ­ã‚»ã‚¹è©³ç´° (ãƒ‡ãƒãƒƒã‚°ç”¨)")

            # 1. åˆ†é¡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®ãƒªã‚¹ãƒˆè¡¨ç¤º (ä¿®æ­£ä¸è¦: getã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤[]ãŒã‚ã‚‹ãŸã‚å®‰å…¨)
            with st.expander(f"1. åˆ†é¡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®å€™è£œãƒªã‚¹ãƒˆ ({len(st.session_state.get('filtered_filenames_list', []))}ä»¶)", expanded=False):
                filtered_list = st.session_state.get('filtered_filenames_list')
                if filtered_list is not None: # ä¸€å¿œãƒã‚§ãƒƒã‚¯ã¯æ®‹ã™
                    if not filtered_list:
                        st.info("åˆ†é¡æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    else:
                        st.dataframe(pd.DataFrame(filtered_list, columns=["ãƒ•ã‚¡ã‚¤ãƒ«å"]), height=300, use_container_width=True)
                else:
                    st.info("ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¯ã¾ã å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚") # ã“ã®ã‚±ãƒ¼ã‚¹ã¯ã»ã¼ç„¡ã„ã¯ãšã ãŒå¿µã®ãŸã‚

            # 2. åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦ ä¸Šä½8ä»¶ã®ãƒªã‚¹ãƒˆè¡¨ç¤º (ä¿®æ­£ä¸è¦: getã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤[]ãŒã‚ã‚‹ãŸã‚å®‰å…¨)
            with st.expander(f"2. åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦ ä¸Šä½8ä»¶ ({len(st.session_state.get('embedding_ranked_list', []))}ä»¶)", expanded=False):
                embed_list = st.session_state.get('embedding_ranked_list')
                if embed_list is not None: # ä¸€å¿œãƒã‚§ãƒƒã‚¯ã¯æ®‹ã™
                    if not embed_list:
                        st.info("åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦ã§ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚ŒãŸå€™è£œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                    else:
                        embed_df = pd.DataFrame(embed_list)
                        if 'score' in embed_df.columns:
                           embed_df['score'] = embed_df['score'].map('{:.3f}'.format)
                        st.dataframe(embed_df[['filename', 'score']], height=300, use_container_width=True)
                else:
                    st.info("åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦è¨ˆç®—ã¯ã¾ã å®Ÿè¡Œã•ã‚Œã¦ã„ãªã„ã‹ã€ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚") # ã“ã®ã‚±ãƒ¼ã‚¹ã¯ã»ã¼ç„¡ã„ã¯ãšã ãŒå¿µã®ãŸã‚

            # 3. Geminié¡ä¼¼åº¦è©•ä¾¡å¾Œã®æœ€çµ‚ãƒªã‚¹ãƒˆè¡¨ç¤º (â˜…ä¿®æ­£ç®‡æ‰€â˜…)
            # --- len() è¨ˆç®—å‰ã«Noneãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ  ---
            gemini_list_for_count = st.session_state.get('top_8_results')
            gemini_count = len(gemini_list_for_count) if gemini_list_for_count is not None else 0
            # --- ä¿®æ­£ã“ã“ã¾ã§ ---
            with st.expander(f"3. Geminié¡ä¼¼åº¦è©•ä¾¡å¾Œ ä¸Šä½8ä»¶ ({gemini_count}ä»¶)", expanded=False): # ä¿®æ­£: äº‹å‰è¨ˆç®—ã—ãŸä»¶æ•°ã‚’ä½¿ç”¨
                gemini_list = st.session_state.get('top_8_results') # expanderå†…éƒ¨ã§ã®åˆ©ç”¨ã®ãŸã‚ã€å†åº¦å–å¾—
                if gemini_list is not None:
                    if not gemini_list:
                        st.info("æœ€çµ‚çš„ãªé¡ä¼¼å€™è£œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                    else:
                        gemini_df = pd.DataFrame(gemini_list)
                        if 'score' in gemini_df.columns:
                           gemini_df['score'] = gemini_df['score'].map('{:.3f}'.format)
                        if 'gemini_score' in gemini_df.columns:
                           gemini_df['gemini_score'] = gemini_df['gemini_score'].apply(lambda x: f'{x:.3f}' if isinstance(x, (int, float)) else ('è©•ä¾¡å¤±æ•—' if x is None else 'N/A'))
                        st.dataframe(gemini_df[['filename', 'gemini_score', 'score']].rename(columns={'score': 'embed_score'}), height=300, use_container_width=True)
                else:
                    st.info("Geminié¡ä¼¼åº¦è©•ä¾¡ã¯ã¾ã å®Ÿè¡Œã•ã‚Œã¦ã„ãªã„ã‹ã€ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")
            # --- ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã“ã“ã¾ã§ ---

            # Display search logs in expander (if available)
            if 'search_logs' in st.session_state and st.session_state.search_logs:
                 with st.expander("ã‚¹ãƒ†ãƒƒãƒ—3: æ¤œç´¢ãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°å‡¦ç†ãƒ­ã‚°", expanded=False):
                     for log_line in st.session_state.search_logs:
                         if log_line.startswith("âŒ"): st.error(log_line)
                         elif log_line.startswith("âš ï¸"): st.warning(log_line)
                         elif log_line.startswith("â„¹ï¸"): st.info(log_line)
                         elif log_line.startswith("âœ…"): st.success(log_line)
                         elif log_line.startswith("ğŸ“Š") or log_line.startswith("â³") or log_line.startswith("ğŸ”„"): st.write(log_line)
                         else: st.text(log_line)

            # --- Display Top 3 Results (Plot) ---
            if st.session_state.top_8_results:
                st.markdown("---")
                st.subheader("é¡ä¼¼åº¦ ä¸Šä½3ä»¶:")
                if st.session_state.search_figure:
                    st.pyplot(st.session_state.search_figure)
                else:
                     st.warning("ä¸Šä½3ç”»åƒã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‹ã€ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

            # --- Display Rank 4-8 in Expander ---
            if st.session_state.top_8_results and len(st.session_state.top_8_results) > 3:
                with st.expander("é¡ä¼¼åº¦ 4ä½ï½8ä½ã‚’è¡¨ç¤º"):
                    results_4_to_8 = st.session_state.top_8_results[3:8]
                    if not results_4_to_8:
                        st.info("4ä½ã‹ã‚‰8ä½ã®ç”»åƒã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                    else:
                        cols = st.columns(2) # 2åˆ—ã§è¡¨ç¤º
                        col_idx = 0
                        for rank_idx, result in enumerate(results_4_to_8):
                            rank = rank_idx + 4
                            with cols[col_idx % 2]:
                                try:
                                    st.image(result["path"], width=200)
                                except FileNotFoundError:
                                    st.error(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {result['filename']}")
                                except Exception as img_e:
                                    st.error(f"ç”»åƒè¡¨ç¤ºã‚¨ãƒ©ãƒ¼ ({result['filename']}): {img_e}")

                                embed_score_str = f"{result.get('score', 'N/A'):.3f}" if isinstance(result.get('score'), (int, float)) else "N/A"
                                gemini_score_val = result.get('gemini_score')
                                gemini_score_str = f"{gemini_score_val:.3f}" if isinstance(gemini_score_val, (int, float)) else "è©•ä¾¡å¤±æ•—" if gemini_score_val is None else "N/A"
                                st.markdown(f"""**Rank {rank}: {result['filename']}**\n- Gemini Sim: {gemini_score_str}\n- Embed Sim: {embed_score_str}""")
                                st.markdown("---") # ç”»åƒã”ã¨ã«åŒºåˆ‡ã‚Šç·š
                            col_idx += 1

            # --- Step 4: Display Product Info Dropdown ---
            if st.session_state.top_8_results:
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‹¡å¼µå­ã‚’é™¤ã„ã¦å“ç•ªãƒªã‚¹ãƒˆã‚’ä½œæˆ
                product_numbers = []
                seen_numbers = set() # é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚
                for res in st.session_state.top_8_results:
                    if 'filename' in res and '.' in res['filename']:
                        p_num = res['filename'].split('.')[0]
                        if p_num not in seen_numbers:
                            product_numbers.append(p_num)
                            seen_numbers.add(p_num)

                if product_numbers:
                    st.markdown("---")
                    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—4: è©³ç´°è¡¨ç¤ºã™ã‚‹å“ç•ªã‚’é¸æŠ")

                    # ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã®é¸æŠçŠ¶æ…‹ã‚’ç¶­æŒ
                    current_selection = st.session_state.get('selected_product_number')
                    current_index = 0 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å…ˆé ­
                    if current_selection in product_numbers:
                        try:
                            current_index = product_numbers.index(current_selection)
                        except ValueError:
                            current_index = 0 # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã‚‚å…ˆé ­
                    elif st.session_state.get('selected_product_number') is not None:
                        # ä»¥å‰é¸æŠã—ã¦ã„ãŸã‚‚ã®ãŒãƒªã‚¹ãƒˆã«ãªã„å ´åˆã‚‚å…ˆé ­
                        current_index = 0
                        st.session_state.selected_product_number = None # é¸æŠã‚’ãƒªã‚»ãƒƒãƒˆ

                    selected_product = st.selectbox(
                        "ä¸Šä½8ä»¶ã‹ã‚‰å“ç•ªã‚’é¸æŠã—ã¦ãã ã•ã„:",
                        options=product_numbers,
                        index=current_index,
                        key="product_select" # key ã‚’æŒ‡å®šã—ã¦çŠ¶æ…‹ã‚’è¿½è·¡
                    )

                    # é¸æŠã•ã‚ŒãŸã‚‰æƒ…å ±ã‚’è¡¨ç¤ºã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
                    if selected_product:
                        # selectbox ã®å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
                        if st.session_state.selected_product_number != selected_product:
                            st.session_state.selected_product_number = selected_product
                            # å†å®Ÿè¡Œã‚’ãƒˆãƒªã‚¬ãƒ¼ã—ã¦è¡¨ç¤ºã‚’æ›´æ–° (selectboxã®å¤‰æ›´è‡ªä½“ãŒãƒˆãƒªã‚¬ãƒ¼ã™ã‚‹ã¯ãš)
                            # st.experimental_rerun() # ä¸è¦ãªå ´åˆãŒå¤šã„

                        # å¸¸ã«ç¾åœ¨ã®é¸æŠã«åŸºã¥ã„ã¦æƒ…å ±ã‚’è¡¨ç¤º
                        display_product_info(st.session_state.selected_product_number)

else:
    st.warning("âš ï¸ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®å‰ææ¡ä»¶ãŒæº€ãŸã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¸Šè¨˜ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


# --- ä¿®ç†ä¾¡æ ¼ä¸€è¦§ ---
st.markdown("---")
st.subheader("ä¿®ç†ä¾¡æ ¼ä¸€è¦§")
if os.path.exists(PRICE_LIST_EXCEL_PATH):
    try:
        df_prices = pd.read_excel(PRICE_LIST_EXCEL_PATH)
        # NaNã‚’ç©ºæ–‡å­—ã«ç½®æ›ã—ã€å…¨åˆ—ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦è¡¨ç¤º
        df_prices_display = df_prices.fillna("").astype(str)
        st.table(df_prices_display)
    except FileNotFoundError:
        st.error(f"âŒ ä¿®ç†ä¾¡æ ¼ä¸€è¦§Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {PRICE_LIST_EXCEL_PATH}")
    except Exception as e:
        st.error(f"âŒ ä¿®ç†ä¾¡æ ¼ä¸€è¦§Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
else:
    st.warning(f"âš ï¸ ä¿®ç†ä¾¡æ ¼ä¸€è¦§Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {PRICE_LIST_EXCEL_PATH}")

# --- æ³¨æ„ç‚¹ ---
st.markdown("---")
st.subheader("æ³¨æ„ç‚¹")
if os.path.exists(NOTES_EXCEL_PATH):
    try:
        df_notes = pd.read_excel(NOTES_EXCEL_PATH)
        # NaNã‚’ç©ºæ–‡å­—ã«ç½®æ›ã—ã€å…¨åˆ—ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦è¡¨ç¤º
        df_notes_display = df_notes.fillna("").astype(str)
        st.table(df_notes_display) # ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
    except Exception as e:
        st.error(f"âŒ æ³¨æ„ç‚¹Excelãƒ•ã‚¡ã‚¤ãƒ« ({NOTES_EXCEL_PATH}) ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
else:
    st.warning(f"âš ï¸ æ³¨æ„ç‚¹Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {NOTES_EXCEL_PATH}")